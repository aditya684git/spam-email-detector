{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHTGMMDxX2sW"
      },
      "source": [
        "---\n",
        "\n",
        "### Importing Libraries\n",
        "\n",
        "This also includes nltk which is Natural Language ToolKit that includes the list of stopwords to be used to pre process the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA5JplhTX2sX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL95PcYTX2sX"
      },
      "source": [
        "### Importing the Dataset\n",
        "This Dataset includes <u>5728</u> mails which are categorized into 'spam' and 'not spam'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm0P6QuSX2sX",
        "outputId": "a3f942b2-cf7f-4670-b7d9-2596e91d7b25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Subject: great nnews  hello , welcome to medzo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Subject: here ' s a hot play in motion  homela...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Subject: save your money buy getting this thin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1\n",
              "5  Subject: great nnews  hello , welcome to medzo...     1\n",
              "6  Subject: here ' s a hot play in motion  homela...     1\n",
              "7  Subject: save your money buy getting this thin...     1"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./emails.csv')\n",
        "df.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9mu3GkDX2sY",
        "outputId": "e589fd3b-4621-4705-a096-aa388502d92e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the Dataset : (5728, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Shape of the Dataset :\",df.shape)\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPhZe1_xX2sY"
      },
      "source": [
        "The above data is Clean and is not missing any values\n",
        "\n",
        "#### Downloading NLTK Stopwords\n",
        "\n",
        "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc. Such words are already captured this in corpus named corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAN1sCIjX2sY",
        "outputId": "b8b0ad31-cb92-4d4c-9a16-dc16d5f5075a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Mayank\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3QkAJUyX2sZ"
      },
      "source": [
        "---\n",
        "\n",
        "### Pre-Processing the Text\n",
        "\n",
        "The mail text is processed in the function 'text_process' wherein the first parts removes all the punctuation in the sentence and then joins the words to create an object separated by commas\n",
        "The second part checks if the words are present in the stopwords(explained in the markdown above) list. If present, they are ignored, if not, they are added to the clearWords variable and the function returns the clearWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFb6hvBaX2sa"
      },
      "outputs": [],
      "source": [
        "def text_process(mail):\n",
        "\n",
        "    removePunc = [char for char in mail if char not in string.punctuation]\n",
        "    removePunc = ''.join(removePunc)\n",
        "\n",
        "    clearWords = [word for word in removePunc.split() if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    return clearWords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAFAxcjOX2sa"
      },
      "source": [
        "The function 'text_process' is applied to the DataFrame 'text' which contains the text in the mail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy8jzZZgX2sa",
        "outputId": "62c82717-bf02-4119-d846-df939c3a1228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [Subject, naturally, irresistible, corporate, ...\n",
              "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2    [Subject, unbelievable, new, homes, made, easy...\n",
              "3    [Subject, 4, color, printing, special, request...\n",
              "4    [Subject, money, get, software, cds, software,...\n",
              "5    [Subject, great, nnews, hello, welcome, medzon...\n",
              "6    [Subject, hot, play, motion, homeland, securit...\n",
              "7    [Subject, save, money, buy, getting, thing, tr...\n",
              "8    [Subject, undeliverable, home, based, business...\n",
              "9    [Subject, save, money, buy, getting, thing, tr...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'].head(10).apply(text_process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCSpFsj3X2sa"
      },
      "source": [
        "### Initializing CountVectorizer from sklearn\n",
        "\n",
        "CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. The value of each cell is nothing but the count of the word in that particular text sample.\n",
        "\n",
        "Tested Runtimes:\n",
        "\n",
        " - CPU - ~5m 50s\n",
        " - GPU - ~0m 11s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt009sm6X2sb",
        "outputId": "3ec0145e-a705-4a1f-9124-5c5d3c96d14b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<5728x37229 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 565908 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = CountVectorizer(analyzer=text_process)\n",
        "vectorizer.fit_transform(df['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgl9IDAxX2sb"
      },
      "source": [
        "Splitting the Data into Training and testing Data (80% Training, 20% Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJZO05A6X2sb"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vect, df['spam'], test_size=0.20, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUTRMP19X2sb",
        "outputId": "8bfaac12-d3f9-40be-a1db-87a2f4b3fa86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4518    0\n",
              "4472    0\n",
              "799     1\n",
              "4809    0\n",
              "1043    1\n",
              "Name: spam, dtype: int64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z-6Q7I-X2sb",
        "outputId": "01b31a23-042d-4cc6-d095-56b5e7a619e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data:  4582\n",
            "Testing Data:  1146\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Data: \",y_train.size)\n",
        "print(\"Testing Data: \",y_test.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZikHgRKX2sb",
        "outputId": "8b04def5-c2b3-4527-8b27-4f3c582e9e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 3638)\t1\n",
            "  (0, 21485)\t1\n",
            "  (0, 32099)\t1\n",
            "  (0, 33656)\t1\n",
            "  (0, 1821)\t1\n",
            "  (0, 9165)\t1\n",
            "  (0, 36899)\t1\n",
            "  (0, 24418)\t1\n",
            "  (0, 2126)\t1\n",
            "  (0, 916)\t1\n",
            "  (0, 19886)\t1\n",
            "  (0, 304)\t1\n",
            "  (0, 6391)\t1\n",
            "  (0, 25629)\t1\n",
            "  (0, 34400)\t1\n",
            "  (0, 21852)\t2\n",
            "  (0, 17693)\t1\n",
            "  (0, 28712)\t1\n",
            "  (0, 28707)\t1\n",
            "  (0, 1223)\t1\n",
            "  (0, 9325)\t1\n",
            "  (0, 35840)\t1\n",
            "  (0, 357)\t1\n",
            "  (0, 32338)\t1\n",
            "  (0, 927)\t2\n",
            "  :\t:\n",
            "  (4581, 26109)\t1\n",
            "  (4581, 18219)\t1\n",
            "  (4581, 10011)\t1\n",
            "  (4581, 20544)\t1\n",
            "  (4581, 14)\t1\n",
            "  (4581, 14669)\t1\n",
            "  (4581, 34784)\t1\n",
            "  (4581, 27016)\t1\n",
            "  (4581, 13342)\t1\n",
            "  (4581, 27303)\t1\n",
            "  (4581, 5629)\t1\n",
            "  (4581, 5218)\t1\n",
            "  (4581, 31966)\t1\n",
            "  (4581, 12780)\t1\n",
            "  (4581, 29073)\t2\n",
            "  (4581, 1588)\t1\n",
            "  (4581, 31940)\t1\n",
            "  (4581, 19651)\t2\n",
            "  (4581, 10597)\t2\n",
            "  (4581, 2796)\t1\n",
            "  (4581, 5539)\t1\n",
            "  (4581, 5990)\t2\n",
            "  (4581, 26460)\t1\n",
            "  (4581, 2246)\t1\n",
            "  (4581, 19507)\t1\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj10GlygX2sc"
      },
      "source": [
        "### Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTbtcZffX2sc"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "classifier = model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyX4EAHkX2sc",
        "outputId": "3dde6e24-7ef5-41cd-8f39-d309aa798785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 1 ... 0 0 0]\n",
            "[0 0 1 ... 0 0 0] \n",
            "\n",
            "[0 0 1 ... 1 0 1]\n",
            "[0 0 1 ... 0 0 1] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "predicted_training = classifier.predict(X_train)\n",
        "predicted_testing = classifier.predict(X_test)\n",
        "\n",
        "print(predicted_training)\n",
        "print(y_train.values,'\\n')\n",
        "print(predicted_testing)\n",
        "print(y_test.values,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL6NEFuLX2sc",
        "outputId": "73a516f6-f19b-44c0-c014-2ccc1e7c44ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3475\n",
            "           1       0.99      1.00      1.00      1107\n",
            "\n",
            "    accuracy                           1.00      4582\n",
            "   macro avg       1.00      1.00      1.00      4582\n",
            "weighted avg       1.00      1.00      1.00      4582\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3466    9]\n",
            " [   2 1105]] \n",
            "\n",
            "Accuracy for training data:  0.9975993016150153\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "predict = classifier.predict(X_train)\n",
        "print(classification_report(y_train, predict))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, predict),'\\n')\n",
        "print('Accuracy for training data: ', accuracy_score(y_train, predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC4RTr64X2sc",
        "outputId": "07f7b3ac-99ee-4614-bace-54916e47c276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 1 ... 1 0 1]\n",
            "[0 0 1 ... 0 0 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       885\n",
            "           1       0.95      0.99      0.97       261\n",
            "\n",
            "    accuracy                           0.99      1146\n",
            "   macro avg       0.97      0.99      0.98      1146\n",
            "weighted avg       0.99      0.99      0.99      1146\n",
            "\n",
            "Confusion Matrix: \n",
            " [[872  13]\n",
            " [  2 259]] \n",
            "\n",
            "Accuracy for testing data:  0.9869109947643979\n"
          ]
        }
      ],
      "source": [
        "print(classifier.predict(X_test))\n",
        "print(y_test.values)\n",
        "predict = classifier.predict(X_test)\n",
        "print(classification_report(y_test, predict))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, predict),'\\n')\n",
        "print('Accuracy for testing data: ', accuracy_score(y_test, predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuCbckjHX2sc"
      },
      "source": [
        "### Testing the model on custom data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9TKh2r4X2sd",
        "outputId": "cc648cb4-9a25-4bd6-bfdf-4572ed0f9fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Mail : ['Subject: unbelievable new homes made easy  im wanting to show you this  homeowner  you have been pre - approved for a $ 454 , 169 home loan at a 3 . 72 fixed rate .  this offer is being extended to you unconditionally and your credit is in no way a factor .  to take advantage of this limited time opportunity  all we ask is that you visit our website and complete  the 1 minute post approval form  look foward to hearing from you ,  dorcas pittman']\n",
            "Actual spam value : [1]\n",
            "Predicted spam value : [1]\n"
          ]
        }
      ],
      "source": [
        "test_mail = df['text'].values[2:3]\n",
        "\n",
        "print(\"Test Mail :\", test_mail)\n",
        "print(\"Actual spam value :\",df['spam'].values[2:3])\n",
        "print(\"Predicted spam value :\",classifier.predict(X_test[-4:-3]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehNx8TmkX2sd"
      },
      "source": [
        "---\n",
        "\n",
        "Concluding this project with a final prediction accuracy of 98.69%"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e8f4faf11bb1c499f7813a67752444782e7c620cd6863ca267fced227a9725a6"
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}